# WARNING: this file is auto-generated by 'build_sync_library.py'
# from the original file 'store.py'
# DO NOT CHANGE! Change the original file instead.
from collections.abc import Sequence
from datetime import datetime
from typing import Any, overload

from key_value.shared.errors import DeserializationError
from key_value.shared.utils.managed_entry import ManagedEntry, verify_dict
from key_value.shared.utils.sanitize import ALPHANUMERIC_CHARACTERS, sanitize_string
from key_value.shared.utils.serialization import SerializationAdapter
from typing_extensions import Self, override

from key_value.sync.code_gen.stores.base import (
    BaseContextManagerStore,
    BaseDestroyCollectionStore,
    BaseEnumerateCollectionsStore,
    BaseStore,
)

try:
    from pymongo import MongoClient
    from pymongo.collection import Collection
    from pymongo.database import Database
    from pymongo.results import DeleteResult  # noqa: TC002
except ImportError as e:
    msg = "MongoDBStore requires py-key-value-aio[mongodb]"
    raise ImportError(msg) from e

DEFAULT_DB = "kv-store-adapter"
DEFAULT_COLLECTION = "kv"

DEFAULT_PAGE_SIZE = 10000
PAGE_LIMIT = 10000

# MongoDB collection name length limit
# https://www.mongodb.com/docs/manual/reference/limits/
# For unsharded collections and views, the namespace length limit is 255 bytes.
# For sharded collections, the namespace length limit is 235 bytes.
# So limit the collection name to 200 bytes
MAX_COLLECTION_LENGTH = 200
COLLECTION_ALLOWED_CHARACTERS = ALPHANUMERIC_CHARACTERS + "_"


class MongoDBAdapter(SerializationAdapter):
    """MongoDB-specific serialization adapter with native BSON datetime support.

    This adapter is optimized for MongoDB, storing:
    - Native BSON datetime types for TTL indexing (created_at, expires_at)
    - Values in value.object (native BSON) or value.string (JSON) fields
    - Support for migration between native and string storage modes

    The native storage mode is recommended for new deployments as it allows
    efficient querying of value fields, while string mode provides backward
    compatibility with older data.
    """

    def __init__(self, *, native_storage: bool = True) -> None:
        """Initialize the MongoDB adapter.

        Args:
            native_storage: If True (default), store value as native BSON dict in value.object field.
                          If False, store as JSON string in value.string field for backward compatibility.
        """
        self.native_storage = native_storage

    def to_storage(self, key: str, entry: ManagedEntry, collection: str | None = None) -> dict[str, Any]:
        """Convert a ManagedEntry to a MongoDB document.

        Args:
            key: The key associated with this entry.
            entry: The ManagedEntry to serialize.
            collection: The collection (unused, for interface compatibility).

        Returns:
            A MongoDB document with key, value, and BSON datetime metadata.
        """
        document: dict[str, Any] = {"key": key, "value": {}}

        # We convert to JSON even if we don't need to, this ensures that the value we were provided
        # can be serialized to JSON which helps ensure compatibility across stores
        json_str = entry.value_as_json

        # Store in appropriate field based on mode
        if self.native_storage:
            document["value"]["object"] = entry.value_as_dict
        else:
            document["value"]["string"] = json_str

        # Add metadata fields as BSON datetimes for TTL indexing
        if entry.created_at:
            document["created_at"] = entry.created_at
        if entry.expires_at:
            document["expires_at"] = entry.expires_at

        return document

    def from_storage(self, data: dict[str, Any] | str) -> ManagedEntry:
        """Convert a MongoDB document back to a ManagedEntry.

        This method supports both native (object) and legacy (string) storage modes,
        and properly handles BSON datetime types for metadata.

        Args:
            data: The MongoDB document to deserialize.

        Returns:
            A ManagedEntry reconstructed from the document.

        Raises:
            DeserializationError: If data is not a dict or is malformed.
        """
        if not isinstance(data, dict):
            msg = "Expected MongoDB document to be a dict"
            raise DeserializationError(msg)

        document = data

        if not (value_field := document.get("value")):
            msg = "Value field not found"
            raise DeserializationError(msg)

        if not isinstance(value_field, dict):
            msg = "Expected `value` field to be an object"
            raise DeserializationError(msg)

        value_holder: dict[str, Any] = verify_dict(obj=value_field)

        entry_data: dict[str, Any] = {}

        # Mongo stores datetimes without timezones as UTC so we mark them as UTC
        # Import timezone here to avoid circular import
        from key_value.shared.utils.time_to_live import timezone

        if created_at_datetime := document.get("created_at"):
            if not isinstance(created_at_datetime, datetime):
                msg = "Expected `created_at` field to be a datetime"
                raise DeserializationError(msg)
            entry_data["created_at"] = created_at_datetime.replace(tzinfo=timezone.utc)

        if expires_at_datetime := document.get("expires_at"):
            if not isinstance(expires_at_datetime, datetime):
                msg = "Expected `expires_at` field to be a datetime"
                raise DeserializationError(msg)
            entry_data["expires_at"] = expires_at_datetime.replace(tzinfo=timezone.utc)

        # Support both native (object) and legacy (string) storage
        if value_object := value_holder.get("object"):
            return ManagedEntry.from_dict(data={"value": value_object, **entry_data})

        if value_string := value_holder.get("string"):
            return ManagedEntry.from_dict(data={"value": value_string, **entry_data}, stringified_value=True)

        msg = "Expected `value` field to be an object with `object` or `string` subfield"
        raise DeserializationError(msg)


class MongoDBStore(BaseEnumerateCollectionsStore, BaseDestroyCollectionStore, BaseContextManagerStore, BaseStore):
    """MongoDB-based key-value store using pymongo."""

    _client: MongoClient[dict[str, Any]]
    _db: Database[dict[str, Any]]
    _collections_by_name: dict[str, Collection[dict[str, Any]]]
    _adapter: SerializationAdapter

    @overload
    def __init__(
        self,
        *,
        client: MongoClient[dict[str, Any]],
        db_name: str | None = None,
        coll_name: str | None = None,
        native_storage: bool = True,
        default_collection: str | None = None,
    ) -> None:
        """Initialize the MongoDB store.

        Args:
            client: The MongoDB client to use.
            db_name: The name of the MongoDB database.
            coll_name: The name of the MongoDB collection.
            native_storage: Whether to use native BSON storage (True, default) or JSON string storage (False).
            default_collection: The default collection to use if no collection is provided.
        """

    @overload
    def __init__(
        self,
        *,
        url: str,
        db_name: str | None = None,
        coll_name: str | None = None,
        native_storage: bool = True,
        default_collection: str | None = None,
    ) -> None:
        """Initialize the MongoDB store.

        Args:
            url: The url of the MongoDB cluster.
            db_name: The name of the MongoDB database.
            coll_name: The name of the MongoDB collection.
            native_storage: Whether to use native BSON storage (True, default) or JSON string storage (False).
            default_collection: The default collection to use if no collection is provided.
        """

    def __init__(
        self,
        *,
        client: MongoClient[dict[str, Any]] | None = None,
        url: str | None = None,
        db_name: str | None = None,
        coll_name: str | None = None,
        native_storage: bool = True,
        default_collection: str | None = None,
    ) -> None:
        """Initialize the MongoDB store.

        Args:
            client: The MongoDB client to use (mutually exclusive with url).
            url: The url of the MongoDB cluster (mutually exclusive with client).
            db_name: The name of the MongoDB database.
            coll_name: The name of the MongoDB collection.
            native_storage: Whether to use native BSON storage (True, default) or JSON string storage (False).
                           Native storage stores values as BSON dicts for better query support.
                           Legacy mode stores values as JSON strings for backward compatibility.
            default_collection: The default collection to use if no collection is provided.
        """

        if client:
            self._client = client
        elif url:
            self._client = MongoClient(url)
        else:
            # Defaults to localhost
            self._client = MongoClient()

        db_name = db_name or DEFAULT_DB
        coll_name = coll_name or DEFAULT_COLLECTION

        self._db = self._client[db_name]
        self._collections_by_name = {}
        self._adapter = MongoDBAdapter(native_storage=native_storage)

        super().__init__(default_collection=default_collection)

    @override
    def __enter__(self) -> Self:
        _ = self._client.__enter__()
        super().__enter__()
        return self

    @override
    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:  # pyright: ignore[reportAny]
        super().__exit__(exc_type, exc_val, exc_tb)
        self._client.__exit__(exc_type, exc_val, exc_tb)

    def _sanitize_collection_name(self, collection: str) -> str:
        """Sanitize a collection name to meet MongoDB naming requirements.

        MongoDB has specific requirements for collection names (length limits, allowed characters).
        This method ensures collection names are compliant by truncating to the maximum allowed length
        and replacing invalid characters with safe alternatives.

        Args:
            collection: The collection name to sanitize.

        Returns:
            A sanitized collection name that meets MongoDB requirements.
        """
        return sanitize_string(value=collection, max_length=MAX_COLLECTION_LENGTH, allowed_characters=COLLECTION_ALLOWED_CHARACTERS)

    @override
    def _setup_collection(self, *, collection: str) -> None:
        # Ensure index on the unique combo key and supporting queries
        collection = self._sanitize_collection_name(collection=collection)

        collection_filter: dict[str, str] = {"name": collection}
        matching_collections: list[str] = self._db.list_collection_names(filter=collection_filter)

        if matching_collections:
            self._collections_by_name[collection] = self._db[collection]
            return

        new_collection: Collection[dict[str, Any]] = self._db.create_collection(name=collection)

        # Index for efficient key lookups
        _ = new_collection.create_index(keys="key")

        # TTL index for automatic expiration of entries when expires_at is reached
        _ = new_collection.create_index(keys="expires_at", expireAfterSeconds=0)

        self._collections_by_name[collection] = new_collection

    @override
    def _get_managed_entry(self, *, key: str, collection: str) -> ManagedEntry | None:
        sanitized_collection = self._sanitize_collection_name(collection=collection)

        if doc := self._collections_by_name[sanitized_collection].find_one(filter={"key": key}):
            try:
                return self._adapter.from_storage(data=doc)
            except DeserializationError:
                return None

        return None

    @override
    def _get_managed_entries(self, *, collection: str, keys: Sequence[str]) -> list[ManagedEntry | None]:
        if not keys:
            return []

        sanitized_collection = self._sanitize_collection_name(collection=collection)

        # Use find with $in operator to get multiple documents at once
        cursor = self._collections_by_name[sanitized_collection].find(filter={"key": {"$in": keys}})

        managed_entries_by_key: dict[str, ManagedEntry | None] = dict.fromkeys(keys)

        for doc in cursor:
            if key := doc.get("key"):
                try:
                    managed_entries_by_key[key] = self._adapter.from_storage(data=doc)
                except DeserializationError:
                    managed_entries_by_key[key] = None

        return [managed_entries_by_key[key] for key in keys]

    @override
    def _put_managed_entry(self, *, key: str, collection: str, managed_entry: ManagedEntry) -> None:
        mongo_doc = self._adapter.to_storage(key=key, entry=managed_entry, collection=collection)

        if not isinstance(mongo_doc, dict):
            msg = "MongoDB adapter must return dict"
            raise TypeError(msg)

        sanitized_collection = self._sanitize_collection_name(collection=collection)

        _ = self._collections_by_name[sanitized_collection].update_one(filter={"key": key}, update={"$set": mongo_doc}, upsert=True)

    @override
    def _put_managed_entries(
        self,
        *,
        collection: str,
        keys: Sequence[str],
        managed_entries: Sequence[ManagedEntry],
        ttl: float | None,
        created_at: datetime,
        expires_at: datetime | None,
    ) -> None:
        if not keys:
            return

        sanitized_collection = self._sanitize_collection_name(collection=collection)

        # Use bulk_write for efficient batch operations
        from pymongo import UpdateOne

        operations: list[UpdateOne] = []
        for key, managed_entry in zip(keys, managed_entries, strict=True):
            mongo_doc = self._adapter.to_storage(key=key, entry=managed_entry, collection=collection)

            if not isinstance(mongo_doc, dict):
                msg = "MongoDB adapter must return dict"
                raise TypeError(msg)

            operations.append(UpdateOne(filter={"key": key}, update={"$set": mongo_doc}, upsert=True))

        _ = self._collections_by_name[sanitized_collection].bulk_write(operations)  # pyright: ignore[reportUnknownMemberType]

    @override
    def _delete_managed_entry(self, *, key: str, collection: str) -> bool:
        sanitized_collection = self._sanitize_collection_name(collection=collection)

        result: DeleteResult = self._collections_by_name[sanitized_collection].delete_one(filter={"key": key})
        return bool(result.deleted_count)

    @override
    def _delete_managed_entries(self, *, keys: Sequence[str], collection: str) -> int:
        if not keys:
            return 0

        sanitized_collection = self._sanitize_collection_name(collection=collection)

        # Use delete_many with $in operator for efficient batch deletion
        result: DeleteResult = self._collections_by_name[sanitized_collection].delete_many(filter={"key": {"$in": keys}})

        return result.deleted_count

    @override
    def _get_collection_names(self, *, limit: int | None = None) -> list[str]:
        limit = min(limit or DEFAULT_PAGE_SIZE, PAGE_LIMIT)

        collections: list[str] = self._db.list_collection_names(filter={})

        return collections[:limit]

    @override
    def _delete_collection(self, *, collection: str) -> bool:
        sanitized_collection = self._sanitize_collection_name(collection=collection)

        _ = self._db.drop_collection(name_or_collection=sanitized_collection)
        if sanitized_collection in self._collections_by_name:
            del self._collections_by_name[sanitized_collection]
        return True

    @override
    def _close(self) -> None:
        self._client.close()
